{"componentChunkName":"component---src-templates-blog-js","path":"/innovation/2025/06/07/azure-generative-search-poc/","result":{"data":{"markdownRemark":{"excerpt":"Over the past few months, I’ve led the design and development of a Proof of Concept (PoC) engagement co-sponsored by Microsoft and a trusted…","id":"b8047925-0fd8-5547-996f-c0fb9dc49085","frontmatter":{"title":"Azure Generative Search POC: Fully formatted facts, Agentic, MCP, MFE","subtitle":"Showcasing GenSearch breakthroughs, secure AI, and hands-on innovation","excerpt":"Over the past few months, I’ve led the design and development of a Proof of Concept (PoC) engagement co-sponsored by Microsoft and a trusted enterprise client.","date":"June 8, 2025","author":"Mark Roxberry","featured":true,"tags":["generative intelligence","Azure","data","search"],"postimage":{"alt":"Generative Search POC","src":{"absolutePath":"/home/runner/work/markrox.dev/markrox.dev/temp/src/posts/2025-06-07-azure-generative-search-poc/post.png","childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAIAAABr+ngCAAAACXBIWXMAAAsTAAALEwEAmpwYAAADDElEQVR42k1Te0iTURw993NuWj4KLbI0t+m27GVYWJrL7AFZTc25LTfXw0U+KUxtU9dLzJak9qLswXSSkaG90BUR/VEYSQ+KWGX9YZRFRFGIRhlov6sGwf3ud7+Pe37n3N85FwhNRtg6zNRAmgp5BpQmKLKEmALxOock9YhoqQ3zCxGdhznbMMsMhQGyDZi5HmFrEboG/EUf4aNIVRaiskXJjgm1Lye2DAS0/Zra8snP0oI4O1tSggX5iNqMCB2nIQixctrwFF5PkYmorSy+THL4Fav7gqpeOPqE84NTLv8QZ7qgrsJiK5dABERDEAKOItMRqeeq5m0XTM1C5RsUdWNXNyt9DNtz77q+wDPvJx31iI1OxJZiQQ5UJsi1CNcQOI1XItqYQmZuFYq6kHsXFjeyO2C5iZw72PmAHejxOvnVp/4tS6rG/AISiEgDpGmAnGgNTGlimhMs5zbLvMQMF5jOxTIama4J+maY22C5JSp7IqntlRR0iPUNXmoblFlc7zitchPUB7GiFsuqkXjov7kaSQ5Be86/8qHfoWf+x1761Xh889ugMiMiA7x7EQZJojWk+MqMCvd0u3ua3T21wh1U3jmprNPf2inZcc0776oo9wbL7RQK3CzvpsjswuwtHMiPrsqSn/bE3huK6/656MVQdM9wVM+IzDMS8nR48v0Rn9bfQsVTwdgoGF2CwcmHpp53lySTw0J0dnDDh+AT74KO9wQ2fg64NjTx+h9J+x/RxV/sbD/2vmbbOtjqKiTtZ6sOMrUdiXugNHJ3edMidD62rgkN332Pf/Q990PiHBA7B73P93ud+sZq+ljJI7a5nanLhZQ6wdiEuN1YXMyt5d2muEhT2dwtXiv2Civ3CUn28bG8giWWsQQrYouwsJAl2BBv5cgYSmsuR476rOErKSU2hQ+yXZoOmRZSLV/Qf7KENlCqVUYo9FCMxVODsPX4dytIvBaROr5JsZEfiQZZSGvKA4kcK0Fx5BdBM343+EN4nvDRErI03n/ykGb52KzlQaL/XGAK30acHJL8Fy6w9O0J75w2AAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/bfbf7fa2f6e15c6fb6db9ee069ac9323/8a036/post.png","srcSet":"/static/bfbf7fa2f6e15c6fb6db9ee069ac9323/76a4f/post.png 750w,\n/static/bfbf7fa2f6e15c6fb6db9ee069ac9323/8a036/post.png 1024w","sizes":"100vw"},"sources":[{"srcSet":"/static/bfbf7fa2f6e15c6fb6db9ee069ac9323/2b382/post.avif 750w,\n/static/bfbf7fa2f6e15c6fb6db9ee069ac9323/6ddc6/post.avif 1024w","type":"image/avif","sizes":"100vw"},{"srcSet":"/static/bfbf7fa2f6e15c6fb6db9ee069ac9323/66907/post.webp 750w,\n/static/bfbf7fa2f6e15c6fb6db9ee069ac9323/2d898/post.webp 1024w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.75},"resize":{"src":"/static/bfbf7fa2f6e15c6fb6db9ee069ac9323/f3583/post.png","height":900,"width":1200}}}}},"html":"<p>Over the past few months, I’ve led the design and development of a Proof of Concept (PoC) engagement co-sponsored by <strong>Microsoft</strong> and a trusted enterprise client. Our mission: deliver a secure, intelligent search assistant that transforms complex document repositories into conversational, explainable insights using Azure’s evolving AI ecosystem.</p>\n<h2>The Mission</h2>\n<p>The PoC focused on enabling <strong>Retrieval-Augmented Generation (RAG)</strong> over enterprise documents using natural language. But we didn’t stop at answering questions. We aimed to demonstrate the future of enterprise LLM systems—systems that are secure, modular, cost-aware, and above all, <em>useful</em>.</p>\n<p>Key goals included:</p>\n<ul>\n<li>Building a <strong>RAG-enabled Generation Search Assistant</strong></li>\n<li>Integrating with <strong>Azure AI Search</strong> (hybrid: vector + keyword)</li>\n<li>Ingesting structured and unstructured data from <strong>Azure Blob Storage</strong></li>\n<li>Supporting <strong>prompt engineering</strong>, <strong>agentic interactions</strong>, and <strong>secure context traceability</strong></li>\n<li>Creating a <strong>prompt engineering workbench</strong> for iterative design and test</li>\n<li>Laying the foundation for <strong>agent-oriented architectures</strong> powered by intelligent model routing</li>\n</ul>\n<h2>Architecture: From Assistant to Agent</h2>\n<p>I designed the architecture to be modular and future-forward. It reflects a shift from monolithic AI calls to <strong>agent-enabled systems</strong> capable of reasoning, switching models, and enforcing control boundaries.</p>\n<h3>Core Components I Architected</h3>\n<ul>\n<li>Azure Blob Storage</li>\n<li>Azure AI Search (hybrid vector and keyword)</li>\n<li>Azure OpenAI + Azure AI Foundry</li>\n<li>Model Router</li>\n<li>Model Context Protocol (MCP)</li>\n<li>App Services layer</li>\n<li>Chainlit-based UI</li>\n<li>Factlit (experimental front end for testing)</li>\n</ul>\n<h3>Agentic and MCP-Enabled Generation</h3>\n<p>By integrating <strong>Model Router</strong> and the <strong>Model Context Protocol (MCP)</strong>, I enabled the assistant to act more like an intelligent agent—capable of orchestrating secure, data-aware, multi-step reasoning.</p>\n<blockquote>\n<p>MCP is an open standard that enables developers to build secure, two-way connections between their data sources and AI-powered tools. In our architecture:</p>\n<ul>\n<li>The assistant acts as an MCP client, connecting to enterprise data systems via MCP servers.</li>\n<li>This allows structured, policy-controlled access to trusted sources during runtime.</li>\n<li>It supports workflows like personalized document filtering, contextual grounding, and real-time data integration.</li>\n</ul>\n</blockquote>\n<h2>Metadata Enrichment and Secure Indexing</h2>\n<p>I developed a custom <strong>Azure AI Indexer and Skillset</strong> with a document ingestion function that queries the client’s metadata database. This enrichment pipeline:</p>\n<ul>\n<li>Adds versioning, project, and permission metadata to document chunks</li>\n<li>Ensures security filters are enforced during search and retrieval</li>\n<li>Supports traceability and access-bound generation logic</li>\n</ul>\n<h2>The Role of Factlit: My AI Architect Toolkit</h2>\n<p>As part of my development workflow, I created <strong>Factlit</strong>—a frontend interface to test prompt engineering, model behaviors, and output types across platforms.</p>\n<p>Using Factlit, I:</p>\n<ul>\n<li>Tuned system prompts and templates</li>\n<li>Ran comparisons across Azure OpenAI, OpenAI, and Anthropic</li>\n<li>Demonstrated access to both <strong>ChromaDB</strong> and <strong>Azure AI Search</strong> as knowledge sources</li>\n<li>Validated \"Fully Formatted Fact\" ingestion strategy, reducing hallucinations to <strong>under 1%</strong> in test queries</li>\n</ul>\n<h2>Prototype Design: Angular Microfrontend Architecture</h2>\n<p>The production-ready prototype is not a standalone app—it’s an <strong>Angular library</strong> designed to be integrated as a <strong>microfrontend</strong>.</p>\n<ul>\n<li>Built as a library to be embedded in existing enterprise applications</li>\n<li>A <strong>host wrapper</strong> was developed for the PoC to simulate the runtime environment</li>\n<li>OIDC tokens (including <code>oid</code> and <code>sub</code>) were used to identify the user and filter responses server-side</li>\n<li>Secure search filtering and project-aware context were demonstrated</li>\n</ul>\n<h2>How We Built the Prototype</h2>\n<ol>\n<li><strong>Document Ingestion</strong> – Chunking, enrichment, and hybrid indexing</li>\n<li><strong>RAG Execution Loop</strong> – Semantic + keyword retrieval → contextual generation</li>\n<li><strong>Prompt Workbench</strong> – Factlit-supported iterative design</li>\n<li><strong>Observability</strong> – Usage logging, traceability, and response inspection</li>\n</ol>\n<h2>Results</h2>\n<ul>\n<li>Grounded, citation-aware responses using enterprise documents</li>\n<li>Secure and dynamic prompt routing via Model Router</li>\n<li>MCP-enabled context integration for enterprise data</li>\n<li>Angular-based microfrontend for easy app embedding</li>\n<li>Hallucination rate reduced to &#x3C;1% using fully formatted fact ingestion</li>\n<li>Semantic caching integration in progress</li>\n</ul>\n<h2>Looking Ahead</h2>\n<h3>1. Data Enrichment</h3>\n<ul>\n<li>SpaCy, LangChain for local</li>\n<li>Azure AI Studio, Cognitive Services for cloud</li>\n<li>Unified pipelines for multimodal enrichment</li>\n</ul>\n<h3>2. Semantic Caching</h3>\n<ul>\n<li>Vector similarity with sliding expiration</li>\n<li>Version-aware invalidation</li>\n<li>Query path reuse and shortcutting</li>\n</ul>\n<h3>3. Prompt Engineering Workbench</h3>\n<ul>\n<li>Prompt versioning, rollback, and scoring</li>\n<li>Controlled A/B testing</li>\n<li>Output grading pipelines</li>\n</ul>\n<h3>4. FinOps for AI</h3>\n<ul>\n<li>Token accounting and usage caps</li>\n<li>Model fallback logic (e.g., GPT-4 → GPT-3.5)</li>\n<li>Spend observability per team/project</li>\n</ul>\n<h3>5. Proliferation: Cloud to SoC</h3>\n<ul>\n<li>On-device quantized models</li>\n<li>Offline AI copilots</li>\n<li>Edge RAG agents with local context</li>\n</ul>\n<h2>Final Reflection</h2>\n<p>This project was about more than building a smart search box. It was a glimpse into what enterprise AI can become when it’s modular, secure, intelligent, and adaptable.</p>\n<p>Microsoft’s support enabled us to push boundaries—and now, with the foundation laid, we’re ready to take the next leap.</p>\n<h2>References &#x26; Further Reading</h2>\n<p>For those interested in the technologies and architectural components mentioned in this post, here are helpful links and resources:</p>\n<h3>Microsoft Azure AI Services</h3>\n<ul>\n<li><a href=\"https://learn.microsoft.com/en-us/azure/search/search-what-is-azure-search\">Azure AI Search (Vector + Hybrid Search)</a></li>\n<li><a href=\"https://learn.microsoft.com/en-us/azure/cognitive-services/openai/overview\">Azure OpenAI Service</a></li>\n<li><a href=\"https://azure.microsoft.com/en-us/products/ai-services/ai-studio/\">Azure AI Studio</a></li>\n<li><a href=\"https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/introducing-azure-ai-foundry/ba-p/4098816\">Azure AI Foundry</a></li>\n<li><a href=\"https://azure.microsoft.com/en-us/products/api-management/\">Azure API Management</a></li>\n</ul>\n<h3>Architecture Concepts</h3>\n<ul>\n<li><a href=\"https://openai.com/blog/chatgpt-retrieval-plugin\">Retrieval-Augmented Generation (RAG) Overview – OpenAI</a></li>\n<li><a href=\"https://www.promptingguide.ai/\">Prompt Engineering Guide (Brevity, Format, Structure)</a></li>\n<li><a href=\"https://gettectonic.com/fully-formatted-facts/\">Fully Formatted Facts</a></li>\n</ul>\n<h3>Agentic Systems</h3>\n<ul>\n<li><a href=\"https://platform.openai.com/docs/guides/function-calling\">OpenAI Function Calling and Agents</a></li>\n<li><a href=\"https://docs.langchain.com/docs/components/agents/\">LangChain Agents</a></li>\n<li><a href=\"https://blog.langchain.dev/langgraph-v0-0-1/\">Autonomous Agents Overview (AutoGPT, LangGraph)</a></li>\n</ul>\n<h3>Model Context Protocol (MCP)</h3>\n<ul>\n<li><a href=\"https://www.anthropic.com/news/model-context-protocol\">Introducing the Model Context Protocol – Anthropic</a></li>\n<li><a href=\"https://github.com/anthropic/model-context-protocol\">MCP Spec Overview</a></li>\n</ul>"}},"pageContext":{"slug":"/innovation/2025/06/07/azure-generative-search-poc/"}},"staticQueryHashes":["1460613570","2052298874","2446865869","717330468"],"slicesMap":{}}